{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================= DATASET: scene =================\n",
        "------- Hamming loss -------\n",
        "BR: 0.224638\n",
        "CC: 0.193701\n",
        "MLkNN: 0.068980\n",
        "BRkNN-a: 0.078177\n",
        "BRkNN-b: 0.077202\n",
        "------- Accuracy score -------\n",
        "BR: 0.193144\n",
        "CC: 0.320234\n",
        "MLkNN: 0.684783\n",
        "BRkNN-a: 0.679766\n",
        "BRkNN-b: 0.732441\n",
        "------- F1 score -------\n",
        "BR: 0.601685\n",
        "CC: 0.539988\n",
        "MLkNN: 0.793433\n",
        "BRkNN-a: 0.771762\n",
        "BRkNN-b: 0.781146\n",
        "================= DATASET: emotions ================="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------- Hamming loss -------\n",
        "BR: 0.207096\n",
        "CC: 0.202970\n",
        "MLkNN: 0.231023\n",
        "BRkNN-a: 0.240099\n",
        "BRkNN-b: 0.264026\n",
        "------- Accuracy score -------\n",
        "BR: 0.282178\n",
        "CC: 0.306931\n",
        "MLkNN: 0.217822\n",
        "BRkNN-a: 0.207921\n",
        "BRkNN-b: 0.193069\n",
        "------- F1 score -------\n",
        "BR: 0.725869\n",
        "CC: 0.734267\n",
        "MLkNN: 0.601991\n",
        "BRkNN-a: 0.602477\n",
        "BRkNN-b: 0.595628\n",
        "================= DATASET: yeast ================="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------- Hamming loss -------\n",
        "BR: 0.256582\n",
        "CC: 0.275588\n",
        "MLkNN: 0.168796\n",
        "BRkNN-a: 0.171912\n",
        "BRkNN-b: 0.181259\n",
        "------- Accuracy score -------\n",
        "BR: 0.116685\n",
        "CC: 0.106870\n",
        "MLkNN: 0.234460\n",
        "BRkNN-a: 0.246456\n",
        "BRkNN-b: 0.193021\n",
        "------- F1 score -------\n",
        "BR: 0.630378\n",
        "CC: 0.605144\n",
        "MLkNN: 0.658766\n",
        "BRkNN-a: 0.670782\n",
        "BRkNN-b: 0.667148\n"
       ]
      }
     ],
     "input": [
      "import sklearn.metrics\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "from skmultilearn.dataset import Dataset\n",
      "from skmultilearn.problem_transform.br import BinaryRelevance\n",
      "from skmultilearn.problem_transform.cc import ClassifierChain\n",
      "from skmultilearn.lazy.mlknn import KNearestNeighbours\n",
      "from skmultilearn.lazy.brknn import BinaryRelevanceKNN\n",
      "\n",
      "datasets = ['scene','emotions','yeast']\n",
      "classifiers = [\n",
      "    BinaryRelevance(GaussianNB()),\n",
      "    ClassifierChain(GaussianNB()),\n",
      "    KNearestNeighbours(),\n",
      "    BinaryRelevanceKNN(extension=BinaryRelevanceKNN.EXTENSION_A),\n",
      "    BinaryRelevanceKNN(extension=BinaryRelevanceKNN.EXTENSION_B)\n",
      "]\n",
      "\n",
      "for dataset in datasets:\n",
      "    train = Dataset.load_dataset_dump(\"skmultilearn/data/\"+dataset+\"-test.dump.bz2\")\n",
      "    test = Dataset.load_dataset_dump(\"skmultilearn/data/\"+dataset+\"-test.dump.bz2\")\n",
      "    predictions = []\n",
      "    for classifier in classifiers:\n",
      "        classifier.fit(train['X'], train['y'])\n",
      "        predictions.append((classifier.BRIEFNAME, classifier.predict(test['X'])))\n",
      "    print(\"================= DATASET: %s =================\" % dataset)\n",
      "    print(\"------- Hamming loss -------\")\n",
      "    for prediction in predictions:\n",
      "        print(\"%s: %f\" % (prediction[0], sklearn.metrics.hamming_loss(test['y'], prediction[1])))\n",
      "    print(\"------- Accuracy score -------\")\n",
      "    for prediction in predictions:\n",
      "        print(\"%s: %f\" % (prediction[0], sklearn.metrics.accuracy_score(test['y'], prediction[1])))\n",
      "    print(\"------- F1 score -------\")\n",
      "    for prediction in predictions:\n",
      "        print(\"%s: %f\" % (prediction[0], sklearn.metrics.f1_score(test['y'], prediction[1])))"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:8d772586ddd021e2f2f28084dbbdd11cc4b1da080d85b034cb9533ab55d6e716"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}