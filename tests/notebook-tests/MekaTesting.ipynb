{
 "metadata": {
  "name": "",
  "signature": "sha256:389aa97958a341b8b346c070b92ceb5a00de1f8955abca3e8efab0ab46b67e74"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A testing ground for classification algorithms\n",
      "==============================================\n",
      "\n",
      "Basically import a data set using the Dataset class and its methods, then import classifiers, initialize the classifier, fit it to test data, predict results, check measures, be happy, maybe compare with meka yet meka sucks in randomness.\n",
      "\n",
      "Import data sets\n",
      "----------------\n",
      "For testing purposes only, as meka uses arff files, that should be store outside of repository for size limit reasons."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skmultilearn.dataset import Dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = Dataset.load_dataset_dump(\"data/scene-test.dump.bz2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Meka, Fit and predict\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from meka.meka import Meka"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meka = Meka(\"meka.classifiers.multilabel.LC\", \"weka.classifiers.bayes.NaiveBayes\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a,b = meka.run(\"/home/niedakh/data/scene/scene-train-meka.arff\", \"/home/niedakh/data/scene/scene-test-meka.arff\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/usr/bin/java -cp \"/home/niedakh/icml/meka-1.7/lib/*\" meka.classifiers.multilabel.LC -threshold 0 -t /home/niedakh/data/scene/scene-train-meka.arff -T /home/niedakh/data/scene/scene-test-meka.arff -verbosity 6 -W weka.classifiers.bayes.NaiveBayes\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification parameters acknowledged by meka"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b['Classifier_info']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'K=14,N=1211'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare with original data and measure\n",
      "--------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.metrics.hamming_loss(test_set['y'],np.array(a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "0.13851727982162765"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.metrics.accuracy_score(test_set['y'],np.array(a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0.54515050167224077"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.metrics.f1_score(test_set['y'],np.array(a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0.62267566475235625"
       ]
      }
     ],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}